# BachelorThesis

In this bachelor thesis we analyse classification results using a 2017 published method
called shap [1]. Explaining how an artificial neural network makes a decision is an inter-
disciplinary research subject combining computer science, mathematics and psychology.
We have studied these explanations from a psychological standpoint and after presenting
our findings, we will propose a method to improve the interpretability of text explanations
using text-hierarchies, without losing much/any accuracy. In addition, the goal was to
test out a framework developed to analyse a multitude of explanation methods. This
Framework will be presented next to our findings and how to use it to create your own
analysis. This Bachelor thesis is addressed at people familiar with artificial neural networks
and other machine learning methods. Background knowledge about artificial intelligence
explainers is not required.
