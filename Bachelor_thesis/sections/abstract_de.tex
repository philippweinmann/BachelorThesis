%% LaTeX2e class for student theses
%% sections/abstract_de.tex
%% 
%% Karlsruhe Institute of Technology
%% Institute for Program Structures and Data Organization
%% Chair for Software Design and Quality (SDQ)
%%
%% Dr.-Ing. Erik Burger
%% burger@kit.edu
%%
%% Version 1.3.5, 2020-06-26

\Abstract
Das Ziel dieser Arbeit ist die Analyse von Klassifizierungen mithilfe der 2017 veröffentlichten Methode Shap \cite{shapPaper}. Erklärungen, wie ein künstliches Neuronales Netz eine Entscheidung trifft, ist ein interdisziplinäres Forschungsgebiet, welches Informatik, Mathematik sowie Psychologie beinhaltet. Wir haben diese Erklärungen von einem psychologischen Standpunkt aus analysiert. Zudem schlagen wir eine Methode vor, um die Interpretierbarkeit von Textklassifizierern zu verbessern ohne signifikant an Genauigkeit zu verlieren. Darüber hinaus war das Ziel dieser Bachelorarbeit ein Framework zu entwickeln um eine vielzahl von Erklärmethoden zu analysieren. Dieses Framework wird neben unseren Resultaten präsentiert. Wir erklären wie es genutzt werden kann um eigene Analysen durchzuführen.
Diese These ist an Personen gerichtet, die mit künstlichen Neuronalen Netzen sowie anderen Machine Learning Methoden vertraut sind. Kenntnisse über Erklärer sind nicht erforderlich.